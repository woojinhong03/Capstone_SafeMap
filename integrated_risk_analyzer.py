import pandas as pd
import numpy as np
from math import radians, cos, sin, asin, sqrt
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import warnings
import sys
import os
import json

# ì§€ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import osmnx as ox
import networkx as nx
from geopy.distance import geodesic
import folium
import requests
import webbrowser
from dotenv import load_dotenv
from scipy.spatial import cKDTree

warnings.filterwarnings('ignore')

if sys.platform == 'win32':
    import locale
    try:
        os.system('chcp 65001 > nul')
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

load_dotenv()  # env íŒŒì¼ì—ì„œ Kakao API key ë¶ˆëŸ¬ì˜¤ê¸°

class PedestrianRiskPredictor:
    def __init__(self):
        try:
            self.data = pd.read_csv('êµí†µì‚¬ê³ ë‹¤ë°œêµ¬ì—­.csv', encoding='utf-8')
        except UnicodeDecodeError:
            try:
                self.data = pd.read_csv('êµí†µì‚¬ê³ ë‹¤ë°œêµ¬ì—­.csv', encoding='cp949')
            except UnicodeDecodeError:
                self.data = pd.read_csv('êµí†µì‚¬ê³ ë‹¤ë°œêµ¬ì—­.csv', encoding='euc-kr')
        self.model = None
        self.scaler = MinMaxScaler()
        self.prepare_data()

    def haversine_distance(self, lat1, lon1, lat2, lon2):
        try:
            lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])

            dlat = lat2 - lat1
            dlon = lon2 - lon1
            a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
            c = 2 * asin(sqrt(a))
            r = 6371
            return c * r
        except:
            return float('inf')

    def prepare_data(self):
        print("ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")

        self.data = self.data.dropna(subset=['X', 'Y'])

        self.data['X'] = pd.to_numeric(self.data['X'], errors='coerce')
        self.data['Y'] = pd.to_numeric(self.data['Y'], errors='coerce')
        self.data['OCCU_TM'] = pd.to_numeric(self.data['OCCU_TM'], errors='coerce')

        self.data = self.data.dropna(subset=['X', 'Y', 'OCCU_TM'])

        severity_scores = {
            'ê²½ìƒ': 1,
            'ë¶€ìƒì‹ ê³ ': 2,
            'ì¤‘ìƒ': 4,
            'ì‚¬ë§': 10
        }
        self.data['severity_score'] = self.data['LCLAS'].map(severity_scores).fillna(1)

        self.data['WLKG'] = self.data['WLKG'].astype(str)
        self.data['SCLAS'] = self.data['SCLAS'].astype(str)

        pedestrian_condition = (
            (self.data['SCLAS'].str.contains('ì°¨ëŒ€ì‚¬ëŒ', na=False)) |
            (self.data['WLKG'].str.contains('O', na=False))
        )
        self.data['pedestrian_weight'] = np.where(pedestrian_condition, 3, 1)

        def get_time_period(hour):
            try:
                hour = int(hour)
                if 0 <= hour < 6:
                    return 'ìƒˆë²½'
                elif 6 <= hour < 12:
                    return 'ì˜¤ì „'
                elif 12 <= hour < 18:
                    return 'ì˜¤í›„'
                else:
                    return 'ì €ë…'
            except:
                return 'ì˜¤ì „'

        self.data['time_period'] = self.data['OCCU_TM'].apply(get_time_period)

        weekend_days = ['í† ìš”ì¼', 'ì¼ìš”ì¼']
        self.data['is_weekend'] = self.data['OCCU_DAY'].isin(weekend_days).astype(int)

        print(f"ì „ì²´ ì‚¬ê³  ë°ì´í„°: {len(self.data)}ê±´")
        print(f"ë³´í–‰ì ê´€ë ¨ ì‚¬ê³ : {len(self.data[self.data['pedestrian_weight'] == 3])}ê±´")

        print("\në°ì´í„° ìƒ˜í”Œ:")
        print(self.data[['LCLAS', 'SCLAS', 'WLKG', 'severity_score', 'pedestrian_weight']].head())

    def calculate_risk_features(self, target_lat, target_lon, radius_km=0.5):
        try:
            distances = self.data.apply(
                lambda row: self.haversine_distance(target_lat, target_lon, row['Y'], row['X']),
                axis=1
            )
            nearby_accidents = self.data[distances <= radius_km].copy()

            if len(nearby_accidents) == 0:
                return {
                    'total_accidents': 0,
                    'pedestrian_accidents': 0,
                    'severity_weighted_score': 0,
                    'pedestrian_weighted_score': 0,
                    'weekend_accidents': 0,
                    'night_accidents': 0,
                    'fatal_accidents': 0
                }

            night_condition = (
                (nearby_accidents['OCCU_TM'] >= 22) |
                (nearby_accidents['OCCU_TM'] <= 6)
            )
            night_accidents = len(nearby_accidents[night_condition])

            fatal_condition = nearby_accidents['LCLAS'].str.contains('ì‚¬ë§', na=False)
            fatal_accidents = len(nearby_accidents[fatal_condition])

            features = {
                'total_accidents': len(nearby_accidents),
                'pedestrian_accidents': len(nearby_accidents[nearby_accidents['pedestrian_weight'] == 3]),
                'severity_weighted_score': (nearby_accidents['severity_score'] * nearby_accidents['pedestrian_weight']).sum(),
                'pedestrian_weighted_score': nearby_accidents['pedestrian_weight'].sum(),
                'weekend_accidents': nearby_accidents['is_weekend'].sum(),
                'night_accidents': night_accidents,
                'fatal_accidents': fatal_accidents
            }

            return features

        except Exception as e:
            print(f"íŠ¹ì„± ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'total_accidents': 0,
                'pedestrian_accidents': 0,
                'severity_weighted_score': 0,
                'pedestrian_weighted_score': 0,
                'weekend_accidents': 0,
                'night_accidents': 0,
                'fatal_accidents': 0
            }

    def create_training_data(self, n_samples=800):
        print("í›ˆë ¨ ë°ì´í„° ìƒì„± ì¤‘...")

        sample_size = min(n_samples // 2, len(self.data))
        sample_indices = np.random.choice(len(self.data), sample_size, replace=False)
        sample_locations = self.data.iloc[sample_indices][['Y', 'X']].values

        lat_min, lat_max = self.data['Y'].min(), self.data['Y'].max()
        lon_min, lon_max = self.data['X'].min(), self.data['X'].max()

        additional_samples = n_samples - len(sample_locations)
        if additional_samples > 0:
            random_lats = np.random.uniform(lat_min, lat_max, additional_samples)
            random_lons = np.random.uniform(lon_min, lon_max, additional_samples)
            random_locations = np.column_stack([random_lats, random_lons])
            sample_locations = np.vstack([sample_locations, random_locations])

        training_features = []
        training_targets = []

        for i, (lat, lon) in enumerate(sample_locations):
            if i % 100 == 0:
                print(f"ì§„í–‰ë¥ : {i}/{len(sample_locations)}")

            features = self.calculate_risk_features(lat, lon)

            import math

            # ì ìˆ˜ë¥¼ 1-30 ë²”ìœ„ë¡œ í™•ì¥í•˜ì—¬ ì°¨ì´ë¥¼ ê·¹ëŒ€í™”
            total_weight = (
                features['total_accidents'] * 0.05 +
                features['pedestrian_accidents'] * 0.4 +
                features['fatal_accidents'] * 1.0 +
                features['night_accidents'] * 0.1 +
                features['weekend_accidents'] * 0.05
            )

            # ì‹¬ê°ë„ ê°€ì¤‘ì¹˜ ì¦ê°€
            severity_factor = features['severity_weighted_score'] * 0.02

            # ê¸°ë³¸ ì ìˆ˜ë¥¼ 1ì ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ì‚¬ê³ ê°€ ìˆì„ ë•Œë§Œ ì ìˆ˜ ì¦ê°€
            if total_weight > 0 or severity_factor > 0:
                # ì§€ìˆ˜ í•¨ìˆ˜ ì‚¬ìš©ìœ¼ë¡œ ì ìˆ˜ ì°¨ì´ë¥¼ ê·¹ëŒ€í™” (ì œí•œ ì—†ìŒ)
                raw_score = (total_weight + severity_factor) ** 1.5 * 3.0
                risk_score = 1.0 + raw_score
            else:
                risk_score = 1.0

            # ìµœëŒ€ê°’ ì œí•œ ì œê±° - ìµœì†Œê°’ë§Œ 1.0ìœ¼ë¡œ ì œí•œ
            risk_score = max(1.0, risk_score)

            training_features.append(list(features.values()))
            training_targets.append(risk_score)

        return np.array(training_features), np.array(training_targets)

    def train_model(self, n_samples=800):
        print("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

        try:
            X, y = self.create_training_data(n_samples)

            X_scaled = self.scaler.fit_transform(X)

            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42
            )

            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            self.model.fit(X_train, y_train)

            train_score = self.model.score(X_train, y_train)
            test_score = self.model.score(X_test, y_test)

            print(f"í›ˆë ¨ ì ìˆ˜: {train_score:.4f}")
            print(f"í…ŒìŠ¤íŠ¸ ì ìˆ˜: {test_score:.4f}")
            print("ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")

        except Exception as e:
            print(f"ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def predict_risk(self, latitude, longitude):
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train_model()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        try:
            features = self.calculate_risk_features(latitude, longitude)

            X_pred = np.array([list(features.values())])
            X_pred_scaled = self.scaler.transform(X_pred)
            risk_score = self.model.predict(X_pred_scaled)[0]

            # ìµœëŒ€ê°’ ì œí•œ ì œê±° - ìµœì†Œê°’ë§Œ 1.0ìœ¼ë¡œ ì œí•œ
            risk_score = max(1, risk_score)

            return {
                'risk_score': round(risk_score, 1),
                'risk_level': self.get_risk_level(risk_score),
                'nearby_accidents': features['total_accidents'],
                'pedestrian_accidents': features['pedestrian_accidents'],
                'details': features
            }

        except Exception as e:
            print(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                'risk_score': 1.0,
                'risk_level': "ë§¤ìš° ë‚®ìŒ",
                'nearby_accidents': 0,
                'pedestrian_accidents': 0,
                'details': {}
            }

    def get_risk_level(self, score):
        if score <= 5:
            return "ë§¤ìš° ë‚®ìŒ"
        elif score <= 20:
            return "ë‚®ìŒ"
        elif score <= 50:
            return "ë³´í†µ"
        elif score <= 100:
            return "ë†’ìŒ"
        else:
            return "ë§¤ìš° ë†’ìŒ"

    def analyze_rectangular_area(self, lat_a, lon_a, lat_b, lon_b, grid_distance_m=75):
        import json

        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train_model()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        center_lat = (lat_a + lat_b) / 2
        center_lon = (lon_a + lon_b) / 2

        half_lat = abs(lat_a - lat_b) / 2
        half_lon = abs(lon_a - lon_b) / 2

        min_lat = center_lat - half_lat * 3
        max_lat = center_lat + half_lat * 3
        min_lon = center_lon - half_lon * 3
        max_lon = center_lon + half_lon * 3

        print(f"ë¶„ì„ ì§€ì—­: ({min_lat:.6f}, {min_lon:.6f}) ~ ({max_lat:.6f}, {max_lon:.6f})")

        lat_step = grid_distance_m / 111000
        avg_lat = (min_lat + max_lat) / 2
        lon_step = grid_distance_m / (111000 * np.cos(np.radians(avg_lat)))

        print(f"ê²©ì ê°„ê²©: ìœ„ë„ {lat_step:.6f}ë„, ê²½ë„ {lon_step:.6f}ë„")

        lat_points = int((max_lat - min_lat) / lat_step) + 1
        lon_points = int((max_lon - min_lon) / lon_step) + 1
        total_points = lat_points * lon_points

        print(f"ì´ {total_points}ê°œ ê²©ìì  ë¶„ì„ ì˜ˆì •")

        danger_centers = []
        grid_count = 0

        lat = min_lat
        while lat <= max_lat:
            lon = min_lon
            while lon <= max_lon:
                result = self.predict_risk(lat, lon)

                weight = round(result['risk_score'], 1)

                danger_centers.append({
                    "lat": round(lat, 6),
                    "lon": round(lon, 6),
                    "weight": weight
                })

                grid_count += 1
                if grid_count % 50 == 0:
                    print(f"ì§„í–‰ë¥ : {grid_count}/{total_points} ê²©ìì  ì²˜ë¦¬ ì™„ë£Œ ({grid_count/total_points*100:.1f}%)")

                lon += lon_step
            lat += lat_step

        print(f"ì´ {len(danger_centers)}ê°œ ê²©ìì  ë¶„ì„ ì™„ë£Œ")

        danger_centers.sort(key=lambda x: (x['lat'], x['lon']))

        return danger_centers

    def save_danger_centers_json(self, danger_centers, filename="danger_centers_output.json"):
        import json

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(danger_centers, f, ensure_ascii=False, indent=4)

        print(f"ê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì§€ë„ ì‹œê°í™” í´ë˜ìŠ¤
class RouteVisualizer:
    def __init__(self):
        self.api_key = os.getenv('Kakao_REST_API_key')

    def interpolate_coordinates_1m(self, route_coords):
        """ê²½ë¡œ ì¢Œí‘œë¥¼ 1m ê°„ê²©ìœ¼ë¡œ ë³´ê°„í•˜ëŠ” í•¨ìˆ˜"""
        interpolated_coords = []

        for i in range(len(route_coords) - 1):
            start_lat, start_lon = route_coords[i]
            end_lat, end_lon = route_coords[i + 1]

            # ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚° (ë¯¸í„°)
            distance = geodesic((start_lat, start_lon), (end_lat, end_lon)).meters

            # 1m ê°„ê²©ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•œ ì ì˜ ê°œìˆ˜ ê³„ì‚°
            num_points = max(1, int(distance))

            # ì‹œì‘ì  ì¶”ê°€
            interpolated_coords.append({
                "latitude": round(start_lat, 8),
                "longitude": round(start_lon, 8)
            })

            # ë³´ê°„ëœ ì ë“¤ ì¶”ê°€
            for j in range(1, num_points):
                ratio = j / num_points

                # ì„ í˜• ë³´ê°„ìœ¼ë¡œ ì¤‘ê°„ ì¢Œí‘œ ê³„ì‚°
                lat = start_lat + (end_lat - start_lat) * ratio
                lon = start_lon + (end_lon - start_lon) * ratio

                interpolated_coords.append({
                    "latitude": round(lat, 8),
                    "longitude": round(lon, 8)
                })

        # ë§ˆì§€ë§‰ ì  ì¶”ê°€
        if route_coords:
            last_lat, last_lon = route_coords[-1]
            interpolated_coords.append({
                "latitude": round(last_lat, 8),
                "longitude": round(last_lon, 8)
            })

        return interpolated_coords

    def kakao_geocode(self, address):
        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {"Authorization": f"KakaoAK {self.api_key}"}
        params = {"query": address}
        response = requests.get(url, headers=headers, params=params)
        if response.status_code != 200:
            print(f"Error: {response.status_code} - {response.text}")
            return None
        result = response.json()
        if 'documents' in result and len(result['documents']) > 0:
            x = float(result['documents'][0]['x'])
            y = float(result['documents'][0]['y'])
            return (y, x)  # ìœ„ë„, ê²½ë„ ìˆœì„œ
        else:
            print("No matching address found.")
            return None

    def visualize_original_route(self, start_location, end_location, shownode=False):
        """ìœ„í—˜ë„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì§€ ì•Šì€ ì›ë˜ ìµœë‹¨ ê²½ë¡œ ì‹œê°í™”"""
        # ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜
        start_coords = self.kakao_geocode(start_location)
        end_coords = self.kakao_geocode(end_location)

        if not start_coords or not end_coords:
            print("ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ì¶œë°œì§€ {start_location} ì¢Œí‘œ:", start_coords)
        print(f"ë„ì°©ì§€ {end_location} ì¢Œí‘œ:", end_coords)

        # ë„ë³´ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë¶ˆëŸ¬ì˜¤ê¸° (ì¶œë°œì§€ ê¸°ì¤€ 3km ë°˜ê²½)
        G = ox.graph_from_point(start_coords, dist=3000, network_type='walk')

        # ì¶œë°œ / ë„ì°© ë…¸ë“œ íƒìƒ‰
        start_node = ox.distance.nearest_nodes(G, X=start_coords[1], Y=start_coords[0])
        end_node = ox.distance.nearest_nodes(G, X=end_coords[1], Y=end_coords[0])

        # ì¼ë°˜ì ì¸ ìµœë‹¨ ê²½ë¡œ íƒìƒ‰ (ê±°ë¦¬ë§Œ ê³ ë ¤)
        route = nx.shortest_path(G, start_node, end_node, weight='length')

        # ê²½ë¡œ ë…¸ë“œ ì¢Œí‘œ ì¶”ì¶œ
        route_latlng = [(G.nodes[n]['y'], G.nodes[n]['x']) for n in route]

        # folium ì§€ë„ ìƒì„± ë° ê²½ë¡œ í‘œì‹œ
        m = folium.Map(location=route_latlng[0], zoom_start=15)
        folium.PolyLine(route_latlng, color='red', weight=5, opacity=0.8).add_to(m)

        if shownode == True:
            # ëª¨ë“  ê¸°ë³¸ ë…¸ë“œ ê²€ì€ ì ìœ¼ë¡œ ì§€ë„ì— ì¶”ê°€
            for node_id, data in G.nodes(data=True):
                folium.CircleMarker(
                    location=(data['y'], data['x']),
                    radius=2,
                    color='black',
                    fill=True,
                    fill_opacity=1
                ).add_to(m)

        # ì¶œë°œ/ë„ì°©ì  ë§ˆì»¤ í‘œì‹œ
        folium.Marker(route_latlng[0], popup=f"{start_location} (ì¶œë°œ)", icon=folium.Icon(color='green')).add_to(m)
        folium.Marker(route_latlng[-1], popup=f"{end_location} (ë„ì°©)", icon=folium.Icon(color='red')).add_to(m)

        # ì§€ë„ HTML ì €ì¥
        out_dir = "data"
        os.makedirs(out_dir, exist_ok=True)
        file_path = os.path.join(out_dir, "original_route_map.html")
        m.save(file_path)
        print(f"ì›ë˜ ê²½ë¡œ ì§€ë„ íŒŒì¼ ì €ì¥: {file_path}")

    def visualize_route(self, start_location, end_location, danger_centers_file="danger_centers_output.json", shownode=False):
        # ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜
        start_coords = self.kakao_geocode(start_location)
        end_coords = self.kakao_geocode(end_location)

        if not start_coords or not end_coords:
            print("ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ì¶œë°œì§€ {start_location} ì¢Œí‘œ:", start_coords)
        print(f"ë„ì°©ì§€ {end_location} ì¢Œí‘œ:", end_coords)

        # ë„ë³´ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë¶ˆëŸ¬ì˜¤ê¸° (ì¶œë°œì§€ ê¸°ì¤€ 3km ë°˜ê²½)
        G = ox.graph_from_point(start_coords, dist=3000, network_type='walk')

        # ìœ„í—˜ì§€ì—­ JSON ë¡œë“œ
        if os.path.exists(danger_centers_file):
            with open(danger_centers_file, 'r', encoding='utf-8') as file:
                danger_centers_with_weight = json.load(file)
        else:
            print(f"ìœ„í—˜ì§€ì—­ íŒŒì¼ {danger_centers_file}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        radius_m = 30  # ìœ„í—˜ì§€ì—­ ë°˜ê²½(m)

        # 1. ë…¸ë“œ ì¢Œí‘œ ë°°ì—´, KD-tree ìƒì„±
        node_coords = np.array([(data['y'], data['x']) for node_id, data in G.nodes(data=True)])
        node_ids = list(G.nodes())
        kdtree = cKDTree(node_coords)

        danger_nodes = {}

        # 2. KD-treeë¡œ ìœ„í—˜ì§€ì—­ ì£¼ë³€ ë…¸ë“œ í›„ë³´êµ° ì„ ë³„, ì •í™• ê±°ë¦¬ ê³„ì‚° í›„ ê°€ì¤‘ì¹˜ í• ë‹¹
        approx_radius_deg = 0.00025  # ì•½ 50m ë°˜ê²½(ìœ„ë„/ê²½ë„ ë‹¨ìœ„ ê·¼ì‚¬)

        for danger_area in danger_centers_with_weight:
            center = (danger_area["lat"], danger_area["lon"])
            weight = danger_area["weight"]

            center_coord = np.array([center[0], center[1]])
            candidate_idxs = kdtree.query_ball_point(center_coord, approx_radius_deg)

            for idx in candidate_idxs:
                node_coord = node_coords[idx]
                dist = geodesic(center, node_coord).meters
                if dist <= radius_m:
                    node_id = node_ids[idx]
                    if node_id not in danger_nodes or danger_nodes[node_id] < weight:
                        danger_nodes[node_id] = weight

        # 3. ê°„ì„ ë³„ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚° (ê±°ë¦¬ íš¨ìœ¨ì„± ìš°ì„ , ì ë‹¹í•œ ìœ„í—˜ë„ íšŒí”¼)
        for u, v, k, data in G.edges(keys=True, data=True):
            base_length = data.get("length", 1.0)
            u_weight = danger_nodes.get(u, 1.0)
            v_weight = danger_nodes.get(v, 1.0)
            max_risk = max(u_weight, v_weight)

            # ê±°ë¦¬ íš¨ìœ¨ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ê³  ìœ„í—˜ë„ëŠ” ìµœì†Œí•œë§Œ ê³ ë ¤
            if max_risk >= 500:
                risk_factor = 1.0 + (max_risk * 0.01)  # 500ì  ì´ìƒ: ì•„ì£¼ ì•½ê°„ íšŒí”¼
            elif max_risk >= 200:
                risk_factor = 1.0 + (max_risk * 0.005)  # 200-500ì : ê±°ì˜ ë¬´ì‹œ
            elif max_risk >= 100:
                risk_factor = 1.0 + (max_risk * 0.002)  # 100-200ì : ë¯¸ë¯¸í•˜ê²Œ ê³ ë ¤
            else:
                risk_factor = 1.0  # 100ì  ë¯¸ë§Œ: ê±°ë¦¬ë§Œ ê³ ë ¤

            data["custom_weight"] = base_length * risk_factor

        # 4. ì¶œë°œ / ë„ì°© ë…¸ë“œ íƒìƒ‰
        start_node = ox.distance.nearest_nodes(G, X=start_coords[1], Y=start_coords[0])
        end_node = ox.distance.nearest_nodes(G, X=end_coords[1], Y=end_coords[0])

        # 5. ê°€ì¤‘ì¹˜(custom_weight) ê¸°ì¤€ ìµœë‹¨ ê²½ë¡œ íƒìƒ‰
        route = nx.shortest_path(G, start_node, end_node, weight='custom_weight')

        # 6. ê²½ë¡œ ë…¸ë“œ ì¢Œí‘œ ì¶”ì¶œ
        route_latlng = [(G.nodes[n]['y'], G.nodes[n]['x']) for n in route]

        # 7. folium ì§€ë„ ìƒì„± ë° ê²½ë¡œ í‘œì‹œ
        m = folium.Map(location=route_latlng[0], zoom_start=15)
        folium.PolyLine(route_latlng, color='blue', weight=5, opacity=0.8).add_to(m)

        if shownode == True:
            # 7-1. ëª¨ë“  ê¸°ë³¸ ë…¸ë“œ ê²€ì€ ì ìœ¼ë¡œ ì§€ë„ì— ì¶”ê°€
            for node_id, data in G.nodes(data=True):
                folium.CircleMarker(
                    location=(data['y'], data['x']),
                    radius=2,
                    color='black',
                    fill=True,
                    fill_opacity=1
                ).add_to(m)

        # 8. ìœ„í—˜ì§€ì—­ ì›í˜• ë§ˆì»¤ ì¶”ê°€ (ì ìˆ˜ì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ìƒ‰ìƒ ë³€ê²½)
        for center in danger_centers_with_weight:
            location = (center['lat'], center['lon'])
            weight = center['weight']
            if weight > 1:
                # ì ìˆ˜ì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ìƒ‰ìƒê³¼ íˆ¬ëª…ë„ ê³„ì‚°
                # 1ì (ì—°í•œ ë…¸ë‘)ì—ì„œ 1000ì (ì§„í•œ ë¹¨ê°•)ê¹Œì§€ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™”

                # ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©)
                import math
                max_score = 1000  # ìµœëŒ€ ì˜ˆìƒ ì ìˆ˜
                normalized = min(1.0, math.log(weight + 1) / math.log(max_score + 1))

                # HSV ìƒ‰ìƒ ê³µê°„ì—ì„œ ìƒ‰ì¡°(Hue) ë³€ê²½: 60ë„(ë…¸ë‘)ì—ì„œ 0ë„(ë¹¨ê°•)ìœ¼ë¡œ
                hue = 60 * (1 - normalized)  # 60(ë…¸ë‘) â†’ 0(ë¹¨ê°•)

                # HSVë¥¼ RGBë¡œ ë³€í™˜
                import colorsys
                rgb = colorsys.hsv_to_rgb(hue/360, 0.8, 0.9)  # ì±„ë„ 0.8, ëª…ë„ 0.9

                # RGBë¥¼ 16ì§„ìˆ˜ ìƒ‰ìƒì½”ë“œë¡œ ë³€í™˜
                color = '#%02x%02x%02x' % (int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))

                # íˆ¬ëª…ë„ë„ ì ìˆ˜ì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™” (ì „ì²´ì ìœ¼ë¡œ ë‚®ê²Œ)
                opacity = 0.1 + (normalized * 0.3)  # 0.2~0.6 ë²”ìœ„ë¡œ ë‚®ì¶¤

                folium.Circle(
                    location, radius=radius_m, color=color, fill=True,
                    fill_color=color, fill_opacity=opacity
                ).add_to(m)

                # í…ìŠ¤íŠ¸ ìƒ‰ìƒë„ ë°°ê²½ì— ë”°ë¼ ì¡°ì •
                text_color = 'white' if normalized > 0.5 else 'black'

                folium.map.Marker(
                    location=location,
                    icon=folium.DivIcon(
                        html=f'<div style="font-size:8pt; font-weight:bold; color:{text_color}; text-align:center; background-color:{color}; border-radius:50%; width:20px; height:20px; line-height:20px; opacity:0.8;">{weight:.0f}</div>'
                    )
                ).add_to(m)
                folium.Circle(
                    location, radius=radius_m, color=color, fill=True,
                    fill_color=color, fill_opacity=opacity,
                    tooltip=f'ìœ„í—˜ë„: {weight:.1f}ì '
                ).add_to(m)

        # 9. ì¶œë°œ/ë„ì°©ì  ë§ˆì»¤ í‘œì‹œ
        folium.Marker(route_latlng[0], popup=start_location, icon=folium.Icon(color='green')).add_to(m)
        folium.Marker(route_latlng[-1], popup=end_location, icon=folium.Icon(color='red')).add_to(m)

        # 10. ì§€ë„ HTML ì €ì¥ ë° ì›¹ ë¸Œë¼ìš°ì € ì—´ê¸°
        out_dir = "data"
        os.makedirs(out_dir, exist_ok=True)
        file_path = os.path.join(out_dir, "route_map.html")
        m.save(file_path)
        print(f"ì €ì¥ëœ ì§€ë„ íŒŒì¼: {file_path}")

        webbrowser.open(f"file://{os.path.abspath(file_path)}")

        # 11. 1m ê°„ê²© ì¢Œí‘œ ìƒì„± ë° JSON ì €ì¥
        print("1m ê°„ê²©ìœ¼ë¡œ ê²½ë¡œ ì¢Œí‘œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        interpolated_coords = self.interpolate_coordinates_1m(route_latlng)

        # 1m ê°„ê²© ì¢Œí‘œ JSON ì €ì¥
        detailed_route_json = {
            "route_info": {
                "route_type": "safety_optimized_path",
                "start_location": start_location,
                "end_location": end_location,
                "total_points": len(interpolated_coords),
                "approximate_distance_meters": len(interpolated_coords)
            },
            "coordinates": interpolated_coords
        }

        detailed_file_path = os.path.join(out_dir, "detailed_route_1m.json")
        with open(detailed_file_path, "w", encoding="utf-8") as f:
            json.dump(detailed_route_json, f, indent=4, ensure_ascii=False)
        print(f"1m ê°„ê²© ìƒì„¸ ê²½ë¡œ íŒŒì¼ ì €ì¥: {detailed_file_path}")

        # 12. ê¸°ì¡´ ê²½ë¡œ ì •ë³´ JSON ì €ì¥ (ì„ íƒ)
        route_json = {
            "route_type": "safety_optimized_path",
            "nodes": {n: {"lat": G.nodes[n]['y'], "lon": G.nodes[n]['x']} for n in route},
            "coords": route_latlng
        }
        with open(os.path.join(out_dir, "route_coords.json"), "w", encoding="utf-8") as f:
            json.dump(route_json, f, indent=4, ensure_ascii=False)
        print(f"ì €ì¥ëœ ë…¸ë“œ ê²½ë¡œ íŒŒì¼: {os.path.join(out_dir, 'route_coords.json')}")

def main():
    try:
        print("=== í†µí•© ë³´í–‰ì ìœ„í—˜ë„ ë¶„ì„ ë° ê²½ë¡œ ì‹œê°í™” ì‹œìŠ¤í…œ ===")

        # 1. ìœ„í—˜ë„ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” ë° í›ˆë ¨
        print("\n1. ë³´í–‰ì ìœ„í—˜ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        predictor = PedestrianRiskPredictor()
        predictor.train_model(n_samples=600)

        # 2. ì‚¬ìš©ìë¡œë¶€í„° ê²½ë¡œ ì¶œë°œì§€/ë„ì°©ì§€ ì…ë ¥ë°›ê¸°
        print("\n=== ê²½ë¡œ ì„¤ì • ===")
        start_location = input("ì¶œë°œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì¢…ê°ì—­): ").strip()
        end_location = input("ë„ì°©ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ëŒ€ë™ì„¸ë¬´ê³ ): ").strip()

        if not start_location:
            start_location = "ì¢…ê°ì—­"
            print("ì¶œë°œì§€ê°€ ì…ë ¥ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ 'ì¢…ê°ì—­'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        if not end_location:
            end_location = "ëŒ€ë™ì„¸ë¬´ê³ "
            print("ë„ì°©ì§€ê°€ ì…ë ¥ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ 'ëŒ€ë™ì„¸ë¬´ê³ 'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # 3. ì¶œë°œì§€/ë„ì°©ì§€ ì¢Œí‘œë¡œ ë¶„ì„ ì§€ì—­ ìë™ ì„¤ì •
        visualizer = RouteVisualizer()

        if not visualizer.api_key:
            print("Kakao API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— Kakao_REST_API_keyë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return

        print(f"\nì¶œë°œì§€ì™€ ë„ì°©ì§€ ì¢Œí‘œë¥¼ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        start_coords = visualizer.kakao_geocode(start_location)
        end_coords = visualizer.kakao_geocode(end_location)

        if not start_coords or not end_coords:
            print("ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¢Œí‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            lat_a, lon_a = 37.570, 126.982
            lat_b, lon_b = 37.5814, 126.9880
        else:
            lat_a, lon_a = start_coords
            lat_b, lon_b = end_coords
            print(f"ì¶œë°œì§€ {start_location} ì¢Œí‘œ: ({lat_a}, {lon_a})")
            print(f"ë„ì°©ì§€ {end_location} ì¢Œí‘œ: ({lat_b}, {lon_b})")

        # 4. ì‚¬ê°í˜• ì§€ì—­ ìœ„í—˜ë„ ë¶„ì„
        print("\n=== ì‚¬ê°í˜• ì§€ì—­ ìœ„í—˜ë„ ë¶„ì„ ===")
        print("ì¶œë°œì§€ì™€ ë„ì°©ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„ ì§€ì—­ì´ ìë™ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("75m ê°„ê²©ìœ¼ë¡œ ìœ„í—˜ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        danger_centers = predictor.analyze_rectangular_area(lat_a, lon_a, lat_b, lon_b)
        predictor.save_danger_centers_json(danger_centers)

        print(f"\nğŸ“Š ì²« 5ê°œ ê²©ìì  ì •ë³´:")
        for i, center in enumerate(danger_centers[:5], 1):
            print(f"{i}. ìœ„ë„: {center['lat']}, ê²½ë„: {center['lon']}, ìœ„í—˜ë„: {center['weight']}/10")

        # 5. ê²½ë¡œ ì‹œê°í™” (ë‘ ê°€ì§€ ë²„ì „)
        print("\n=== ê²½ë¡œ ì‹œê°í™” ===")

        # 5-1. ì›ë˜ ìµœë‹¨ ê²½ë¡œ (ìœ„í—˜ë„ ë¯¸ê³ ë ¤)
        print(f"\n1. ì›ë˜ ìµœë‹¨ ê²½ë¡œ ì§€ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤... ({start_location} â†’ {end_location})")
        visualizer.visualize_original_route(start_location, end_location, shownode=False)

        # 5-2. ì•ˆì „ ìµœì í™” ê²½ë¡œ (ìœ„í—˜ë„ ê³ ë ¤)
        print(f"\n2. ì•ˆì „ ìµœì í™” ê²½ë¡œ ì§€ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤... ({start_location} â†’ {end_location})")
        visualizer.visualize_route(start_location, end_location, shownode=False)

        print("\në‘ ê°€ì§€ ê²½ë¡œ ì§€ë„ê°€ ëª¨ë‘ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")

        print("\nâœ… í†µí•© ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ğŸ“„ ìƒì„±ëœ íŒŒì¼:")
        print("- danger_centers_output.json: ìœ„í—˜ë„ ê²©ì ë°ì´í„°")
        print("\nğŸ“ ì›ë˜ ìµœë‹¨ ê²½ë¡œ (ìœ„í—˜ë„ ë¯¸ê³ ë ¤):")
        print("- data/original_route_map.html: ì›ë˜ ìµœë‹¨ ê²½ë¡œ ì§€ë„")
        print("\nğŸ›¡ï¸ ì•ˆì „ ìµœì í™” ê²½ë¡œ (ìœ„í—˜ë„ ê³ ë ¤):")
        print("- data/route_map.html: ì•ˆì „ ìµœì í™” ê²½ë¡œ ì§€ë„")
        print("- data/route_coords.json: ì•ˆì „ ê²½ë¡œ ì¢Œí‘œ ë°ì´í„°")
        print("- data/detailed_route_1m.json: ì•ˆì „ ê²½ë¡œ 1m ê°„ê²© ì¢Œí‘œ")

    except Exception as e:
        print(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("CSV íŒŒì¼ ê²½ë¡œì™€ ë°ì´í„° í˜•ì‹, API í‚¤ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()